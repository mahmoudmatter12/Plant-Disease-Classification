{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae81844a",
   "metadata": {},
   "source": [
    "# Plant Disease Classification with ResNet50\n",
    "\n",
    "This notebook demonstrates plant disease classification using transfer learning with ResNet50.\n",
    "\n",
    "## Prerequisites\n",
    "- Python 3.10.x\n",
    "- Virtual environment (recommended)\n",
    "- Internet connection for downloading dataset and models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886b9da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ” COMPREHENSIVE DEPENDENCY CHECK\n",
      "============================================================\n",
      "ğŸ Python Version Check\n",
      "   Current: 3.10.19\n",
      "   Required: 3.10.x\n",
      "   âœ… Python version is compatible!\n",
      "\n",
      "ğŸ“¦ Core Dependencies:\n",
      "   âœ… kagglehub: 0.3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahmoud-matter/hnu-projects/ai-skills/MachinLearningModels/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-12-12 15:46:24.906179: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… numpy: 2.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:46:24.925129: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-12 15:46:25.485048: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-12 15:46:28.834740: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-12 15:46:28.838298: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… tensorflow: 2.20.0\n",
      "   âœ… PIL: 12.0.0\n",
      "\n",
      "ğŸ“¦ Optional Dependencies:\n",
      "   âŒ matplotlib: NOT INSTALLED\n",
      "   âŒ seaborn: NOT INSTALLED\n",
      "\n",
      "============================================================\n",
      "âœ… All required dependencies are installed!\n",
      "   You can proceed to the next cell.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Comprehensive Dependency Checker\n",
    "This cell checks all required dependencies before proceeding.\n",
    "Run this cell first to ensure your environment is properly configured.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "# Try to import packaging for version comparison\n",
    "try:\n",
    "    from packaging import version\n",
    "    HAS_PACKAGING = True\n",
    "except ImportError:\n",
    "    HAS_PACKAGING = False\n",
    "    print(\"âš ï¸  Note: 'packaging' module not available - version checking will be limited\")\n",
    "\n",
    "def check_python_version():\n",
    "    \"\"\"Check if Python version is compatible\"\"\"\n",
    "    required_major, required_minor = 3, 10\n",
    "    current_version = sys.version_info\n",
    "    is_compatible = (current_version.major == required_major and \n",
    "                    current_version.minor >= required_minor)\n",
    "    \n",
    "    print(f\"ğŸ Python Version Check\")\n",
    "    print(f\"   Current: {current_version.major}.{current_version.minor}.{current_version.micro}\")\n",
    "    print(f\"   Required: {required_major}.{required_minor}.x\")\n",
    "    \n",
    "    if is_compatible:\n",
    "        print(\"   âœ… Python version is compatible!\")\n",
    "    else:\n",
    "        print(f\"   âŒ ERROR: Python {required_major}.{required_minor}.x is required!\")\n",
    "        raise RuntimeError(f\"Python {required_major}.{required_minor}.x required, got {current_version.major}.{current_version.minor}\")\n",
    "    \n",
    "    return is_compatible\n",
    "\n",
    "def check_package(package_name, min_version=None, import_name=None):\n",
    "    \"\"\"Check if a package is installed and optionally verify version\"\"\"\n",
    "    import_name = import_name or package_name\n",
    "    try:\n",
    "        module = importlib.import_module(import_name)\n",
    "        installed_version = getattr(module, '__version__', 'unknown')\n",
    "        \n",
    "        if min_version and installed_version != 'unknown' and HAS_PACKAGING:\n",
    "            try:\n",
    "                if version.parse(installed_version) < version.parse(min_version):\n",
    "                    print(f\"   âš ï¸  {package_name}: {installed_version} (requires >= {min_version})\")\n",
    "                    return False\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print(f\"   âœ… {package_name}: {installed_version}\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(f\"   âŒ {package_name}: NOT INSTALLED\")\n",
    "        return False\n",
    "\n",
    "def install_package(package_spec):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_spec], \n",
    "                            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Main dependency check\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ” COMPREHENSIVE DEPENDENCY CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check Python version\n",
    "check_python_version()\n",
    "print()\n",
    "\n",
    "# Check core dependencies\n",
    "print(\"ğŸ“¦ Core Dependencies:\")\n",
    "dependencies = {\n",
    "    'kagglehub': None,\n",
    "    'numpy': '1.23.5',\n",
    "    'tensorflow': '2.15.0',\n",
    "    'PIL': None,  # Pillow\n",
    "}\n",
    "\n",
    "missing_packages = []\n",
    "for pkg, min_ver in dependencies.items():\n",
    "    if not check_package(pkg, min_ver):\n",
    "        missing_packages.append(pkg)\n",
    "\n",
    "print()\n",
    "\n",
    "# Check optional dependencies\n",
    "print(\"ğŸ“¦ Optional Dependencies:\")\n",
    "optional_deps = ['matplotlib', 'seaborn']\n",
    "for pkg in optional_deps:\n",
    "    check_package(pkg)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"âš ï¸  Missing packages: {', '.join(missing_packages)}\")\n",
    "    print(\"   Please install them using: %pip install <package_name>\")\n",
    "    print(\"   Or install all requirements: %pip install -r requirements.txt\")\n",
    "else:\n",
    "    print(\"âœ… All required dependencies are installed!\")\n",
    "    print(\"   You can proceed to the next cell.\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12814c73",
   "metadata": {},
   "source": [
    "## Install and Import KaggleHub\n",
    "\n",
    "Install kagglehub if not already installed, then download the plant disease dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e644ebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… kagglehub is already installed\n"
     ]
    }
   ],
   "source": [
    "# Install kagglehub if not already installed\n",
    "try:\n",
    "    import kagglehub\n",
    "    print(\"âœ… kagglehub is already installed\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ Installing kagglehub...\")\n",
    "    %pip install -q kagglehub\n",
    "    import kagglehub\n",
    "    print(\"âœ… kagglehub installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc184d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Downloading plant disease dataset from Kaggle...\n",
      "âœ… Dataset downloaded to: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1\n",
      "âœ… Found PlantVillage folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage\n",
      "ğŸ“Š Found 15 class folders\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # Download latest version\n",
    "    print(\"ğŸ“¥ Downloading plant disease dataset from Kaggle...\")\n",
    "    kaggle_path = kagglehub.dataset_download(\"emmarex/plantdisease\")\n",
    "    print(f\"âœ… Dataset downloaded to: {kaggle_path}\")\n",
    "    \n",
    "    # Find the PlantVillage folder within the Kaggle dataset\n",
    "    # The dataset might have the PlantVillage folder directly or inside a subfolder\n",
    "    dataset_path = None\n",
    "    \n",
    "    # Check common locations\n",
    "    possible_paths = [\n",
    "        os.path.join(kaggle_path, \"PlantVillage\"),\n",
    "        os.path.join(kaggle_path, \"archive\", \"PlantVillage\"),\n",
    "        kaggle_path\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path) and os.path.isdir(path):\n",
    "            # Check if this looks like the PlantVillage folder (has subdirectories)\n",
    "            subdirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "            if len(subdirs) > 5:  # PlantVillage should have many class folders\n",
    "                dataset_path = path\n",
    "                break\n",
    "    \n",
    "    # If not found, search recursively\n",
    "    if dataset_path is None:\n",
    "        print(\"ğŸ” Searching for PlantVillage folder...\")\n",
    "        for root, dirs, files in os.walk(kaggle_path):\n",
    "            if \"PlantVillage\" in dirs:\n",
    "                candidate = os.path.join(root, \"PlantVillage\")\n",
    "                if os.path.isdir(candidate):\n",
    "                    subdirs = [d for d in os.listdir(candidate) if os.path.isdir(os.path.join(candidate, d))]\n",
    "                    if len(subdirs) > 5:\n",
    "                        dataset_path = candidate\n",
    "                        break\n",
    "    \n",
    "    if dataset_path is None:\n",
    "        raise FileNotFoundError(\"Could not find PlantVillage folder in the downloaded dataset\")\n",
    "    \n",
    "    # Validate dataset path\n",
    "    if not os.path.exists(dataset_path):\n",
    "        raise FileNotFoundError(f\"Dataset path does not exist: {dataset_path}\")\n",
    "    \n",
    "    if not os.path.isdir(dataset_path):\n",
    "        raise NotADirectoryError(f\"Dataset path is not a directory: {dataset_path}\")\n",
    "    \n",
    "    print(f\"âœ… Found PlantVillage folder: {dataset_path}\")\n",
    "    \n",
    "    # Count classes to verify dataset\n",
    "    class_folders = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "    print(f\"ğŸ“Š Found {len(class_folders)} class folders\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error downloading or locating dataset: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17187ea",
   "metadata": {},
   "source": [
    "## Extract ZIP File (if needed)\n",
    "\n",
    "Check if the dataset needs to be extracted from a ZIP file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc92c3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… No zip files found - dataset is already extracted from Kaggle\n",
      "âœ… Using dataset path: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # Check if we need to extract a zip file from the Kaggle dataset\n",
    "    # Kaggle usually extracts automatically, but let's check for zip files\n",
    "    if 'kaggle_path' not in globals():\n",
    "        raise NameError(\"kaggle_path not defined. Please run the previous cell first.\")\n",
    "    \n",
    "    if not os.path.exists(kaggle_path):\n",
    "        raise FileNotFoundError(f\"Kaggle path does not exist: {kaggle_path}\")\n",
    "    \n",
    "    zip_files = [f for f in os.listdir(kaggle_path) if f.endswith('.zip')]\n",
    "    \n",
    "    if zip_files:\n",
    "        print(f\"ğŸ“¦ Found zip file(s): {zip_files}\")\n",
    "        zip_path = os.path.join(kaggle_path, zip_files[0])\n",
    "        \n",
    "        if not os.path.exists(zip_path):\n",
    "            raise FileNotFoundError(f\"Zip file not found: {zip_path}\")\n",
    "        \n",
    "        extract_path = kaggle_path\n",
    "        print(f\"ğŸ“‚ Extracting {zip_files[0]}...\")\n",
    "        \n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "                z.extractall(extract_path)\n",
    "            print(\"âœ… Zip file extracted successfully!\")\n",
    "        except zipfile.BadZipFile:\n",
    "            raise ValueError(f\"Invalid zip file: {zip_path}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error extracting zip file: {e}\")\n",
    "        \n",
    "        # Re-find PlantVillage after extraction\n",
    "        print(\"ğŸ” Re-locating PlantVillage folder...\")\n",
    "        for root, dirs, files in os.walk(kaggle_path):\n",
    "            if \"PlantVillage\" in dirs:\n",
    "                candidate = os.path.join(root, \"PlantVillage\")\n",
    "                if os.path.isdir(candidate):\n",
    "                    dataset_path = candidate\n",
    "                    break\n",
    "        \n",
    "        if 'dataset_path' in locals() and dataset_path:\n",
    "            print(f\"âœ… Updated dataset path: {dataset_path}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Could not find PlantVillage folder after extraction\")\n",
    "    else:\n",
    "        print(\"âœ… No zip files found - dataset is already extracted from Kaggle\")\n",
    "        if 'dataset_path' in globals():\n",
    "            print(f\"âœ… Using dataset path: {dataset_path}\")\n",
    "        else:\n",
    "            raise NameError(\"dataset_path not defined. Please run the previous cell first.\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error in zip extraction: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c400ebe",
   "metadata": {},
   "source": [
    "List Files in a Folder ğŸ“‚\n",
    "\n",
    "Quickly see all files in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e996a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Potato___Early_blight', 'Tomato__Tomato_mosaic_virus', 'Tomato_Late_blight', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato__Target_Spot', 'Potato___healthy', 'Tomato_Septoria_leaf_spot', 'Tomato_Early_blight', 'Potato___Late_blight', 'Tomato_healthy', 'Tomato_Bacterial_spot', 'Tomato_Leaf_Mold', 'Pepper__bell___healthy', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Pepper__bell___Bacterial_spot']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Use the Kaggle dataset path (defined in cell 2)\n",
    "print(os.listdir(dataset_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c60e0",
   "metadata": {},
   "source": [
    " Explore Folder Structure in Python ğŸ“‚\n",
    "\n",
    "Print folder paths and a few files inside each folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82ab8c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Potato___Early_blight\n",
      "   - 583fa343-d5be-414b-bd95-f674313bd882___RS_Early.B 7681.JPG\n",
      "   - 06ac6596-8d65-46dd-a343-a2209f3480e4___RS_Early.B 6921.JPG\n",
      "   - b35e4c48-e54e-4e42-a399-b236209314f4___RS_Early.B 8231.JPG\n",
      "   - b05850b8-bfb9-487d-b0ba-8f406eba933e___RS_Early.B 6936.JPG\n",
      "   - c10de41b-4c38-41c4-b278-600071051453___RS_Early.B 8093.JPG\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato__Tomato_mosaic_virus\n",
      "   - 7a6e4837-d63d-465a-abae-ef857bf43e2d___PSU_CG 2117.JPG\n",
      "   - b5987570-3fbe-4a4c-9790-1d55bcfd2c61___PSU_CG 2288.JPG\n",
      "   - 86965ac5-b790-4218-a3c6-216d10da5211___PSU_CG 2066.JPG\n",
      "   - 9ec78399-de3a-4431-a5fc-e100406c5642___PSU_CG 2275.JPG\n",
      "   - 9a3941e6-32bc-4417-862b-2f03e4040b65___PSU_CG 2159.JPG\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato_Late_blight\n",
      "   - e4d14fec-dc38-4e88-ac83-1f1b75be5de7___RS_Late.B 6450.JPG\n",
      "   - b68b50e0-52b1-4ba0-98df-8080ffaf3a70___GHLB_PS Leaf 26 Day 16.jpg\n",
      "   - 52c38d27-ff5d-4eb0-83a4-4dea0a7bc51b___GHLB2 Leaf 73.JPG\n",
      "   - 1c8bf271-8455-42f5-8e9f-8a92418116f9___GHLB2 Leaf 9066.JPG\n",
      "   - 44728e89-49f7-435e-b4d9-a64a7a3f2317___RS_Late.B 7116.JPG\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato__Tomato_YellowLeaf__Curl_Virus\n",
      "   - 1cc5fa35-fde4-4b2d-b543-f0b7e6f5eb79___UF.GRC_YLCV_Lab 02152.JPG\n",
      "   - 42cdc8a5-8010-4486-8dcd-46fc67290412___YLCV_GCREC 2305.JPG\n",
      "   - 329b304a-e702-452d-9c51-8d037841bdd6___YLCV_NREC 2569.JPG\n",
      "   - 4bc2aee8-39cb-4d93-a92f-eb193d4a9624___YLCV_NREC 2449.JPG\n",
      "   - 6c0da973-414f-473f-8cb4-f280b39abb74___UF.GRC_YLCV_Lab 08524.JPG\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato__Target_Spot\n",
      "   - 47139cf4-a587-49f2-a935-a2d88a7bb48a___Com.G_TgS_FL 1071.JPG\n",
      "   - a5afdb8f-fc49-47c9-b3fa-7e1beb24777e___Com.G_TgS_FL 7929.JPG\n",
      "   - f551fe31-b0e2-4526-b22d-4e3dc1181efa___Com.G_TgS_FL 0052.JPG\n",
      "   - 6109be79-316c-4075-9a0f-556cde1c0977___Com.G_TgS_FL 0727.JPG\n",
      "   - 0fe7d644-dc8b-49f7-9a41-33ec029f6437___Com.G_TgS_FL 8274.JPG\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Potato___healthy\n",
      "   - 71c06efe-089f-49b3-beed-095bd7640e32___RS_HL 1947.JPG\n",
      "   - 3c0d6888-c7e1-4cf8-9c25-9a0b8c62ba72___RS_HL 1780.JPG\n",
      "   - 875d6ded-5f01-495c-a945-ad2e17f87f91___RS_HL 1848.JPG\n",
      "   - b4031970-60ea-4739-9fed-6c81be1bad1c___RS_HL 1752.JPG\n",
      "   - 799b10e8-ba67-4e08-9abe-748789572ad1___RS_HL 1881.JPG\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato_Septoria_leaf_spot\n",
      "   - 02d2c484-8bdb-4ef2-8d07-0bdb3ac330cc___Matt.S_CG 0975.JPG\n",
      "   - 583887a3-a071-4735-8d92-821d1f2e5ef0___Matt.S_CG 6045.JPG\n",
      "   - c503232e-912b-435b-a590-85cded918960___Keller.St_CG 2038.JPG\n",
      "   - 296f4660-5675-43b8-8b1f-20e8e9b228b7___JR_Sept.L.S 2612.JPG\n",
      "   - fbae6253-c516-4e47-bb84-9ab675ed5d0e___Matt.S_CG 1419.JPG\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato_Early_blight\n",
      "   - 1d1d79c6-824d-4c48-bd59-c83a5cf29229___RS_Erly.B 9547.JPG\n",
      "   - 18ec9a60-a4e3-4dd7-805f-fe9eaf526c2f___RS_Erly.B 8405.JPG\n",
      "   - d032b2d0-3c5b-4f1d-9532-4fd09cbd5482___RS_Erly.B 7689.JPG\n",
      "   - 5ac54e63-40a4-4651-a900-fd3ab4d32bae___RS_Erly.B 7727.JPG\n",
      "   - de96e7a2-6de3-4699-9680-9eb4d4e215c8___RS_Erly.B 9445.JPG\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Potato___Late_blight\n",
      "   - ff7160f9-f8d7-4576-82b8-009bf1b63b3b___RS_LB 4974.JPG\n",
      "   - 9d0f96e2-93c7-4202-b1d1-6f878c066be7___RS_LB 3106.JPG\n",
      "   - df40ffa7-8efd-4720-8786-a30b9011dcfc___RS_LB 4150.JPG\n",
      "   - 43396f0d-f05b-4dce-a209-9edcbd62d39c___RS_LB 4407.JPG\n",
      "   - 8a2f2feb-3738-4675-9cb6-b1911a056dd1___RS_LB 2601.JPG\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato_healthy\n",
      "   - 5393abd2-b4e2-4af2-94d4-c52c919fc157___RS_HL 0322.JPG\n",
      "   - 83a8e340-30f9-4e2f-b825-a1078d5c63cf___RS_HL 0033.JPG\n",
      "   - 79debbff-9c0f-4a5c-a4c7-4b2bc97406dc___RS_HL 0244.JPG\n",
      "   - cb1900be-7286-4ff9-89d2-c27641e91d2d___RS_HL 0071.JPG\n",
      "   - 9b2a3f9a-f450-471d-928c-270126c8602a___RS_HL 9758.JPG\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato_Bacterial_spot\n",
      "   - 5512c9ea-9177-4860-8035-c4f8b2025693___GCREC_Bact.Sp 5651.JPG\n",
      "   - 37592d17-06d6-492a-a469-3726396ad71b___GCREC_Bact.Sp 5560.JPG\n",
      "   - 0c5eb8e4-e0fb-424a-8873-e43f9a6121ef___GCREC_Bact.Sp 6281.JPG\n",
      "   - e5ebe0ed-8be8-46c8-a209-32b00ad5f65e___GCREC_Bact.Sp 6033.JPG\n",
      "   - 0b233197-cd35-4031-80c2-610e7e3a046b___GCREC_Bact.Sp 6095.JPG\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato_Leaf_Mold\n",
      "   - 802b8083-7628-4974-8d38-ffe2d82ad62f___Crnl_L.Mold 8997.JPG\n",
      "   - 6e8f1122-d902-408e-a33e-2d5514112e38___Crnl_L.Mold 6944.JPG\n",
      "   - a6626e49-1ba7-4b37-9490-aff2b2ec03eb___Crnl_L.Mold 7141.JPG\n",
      "   - a7ea5602-9cd1-444e-bce8-ed314ddda894___Crnl_L.Mold 9101.JPG\n",
      "   - 150f6844-796d-4960-b42b-629f25806bfb___Crnl_L.Mold 7096.JPG\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Pepper__bell___healthy\n",
      "   - 566dce25-a478-4995-b7be-08ff6f130703___JR_HL 8558.JPG\n",
      "   - 7ace1bb9-5005-4a1b-a207-7d55e65c6652___JR_HL 7875.JPG\n",
      "   - 636b11a4-ccc6-496a-923e-72f6332a91b1___JR_HL 8405.JPG\n",
      "   - 7267607f-acf4-40fb-b691-e46ade9b87c9___JR_HL 8758.JPG\n",
      "   - 2d5f93aa-ee53-49eb-ac82-cd0d4b9359c6___JR_HL 8481.JPG\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato_Spider_mites_Two_spotted_spider_mite\n",
      "   - 80cd157e-4865-43f3-a0c6-8e3d72e35316___Com.G_SpM_FL 1154.JPG\n",
      "   - 771c1ccc-fa2f-436c-bf70-bd474f49bbc1___Com.G_SpM_FL 9257.JPG\n",
      "   - be960347-691b-4378-b9a9-4fbbb456fc76___Com.G_SpM_FL 8858.JPG\n",
      "   - 64603741-48ad-46ad-96fd-33b1f1269a38___Com.G_SpM_FL 8823.JPG\n",
      "   - baf28c1c-ff4a-4245-842f-dafdb5c43826___Com.G_SpM_FL 1650.JPG\n",
      "---------------\n",
      "ğŸ“ Folder: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Pepper__bell___Bacterial_spot\n",
      "   - d7010297-6cb4-435d-ad31-12758c1520c8___JR_B.Spot 8940.JPG\n",
      "   - 875f41e8-cd70-44f4-a17c-c8b77fed406c___JR_B.Spot 8902.JPG\n",
      "   - 0e57b44f-bb06-43ec-8688-5a7985b461e7___JR_B.Spot 8970.JPG\n",
      "   - dec101b9-596c-420a-b3d9-112ee8cbf72f___JR_B.Spot 3105.JPG\n",
      "   - 3cc682be-f9eb-4464-a385-7265d8871b03___NREC_B.Spot 1865.JPG\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Use the Kaggle dataset path (defined in cell 2)\n",
    "root = dataset_path\n",
    "\n",
    "for path, dirs, files in os.walk(root):\n",
    "    print(f\"ğŸ“ Folder: {path}\")\n",
    "    for f in files[:5]: \n",
    "        print(\"   -\", f)\n",
    "    print(\"---------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aee2de",
   "metadata": {},
   "source": [
    "Count Images in Each Class Folder ğŸ–¼ï¸\n",
    "\n",
    "Check how many images are in each subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cc79feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potato___Early_blight: 1000 images\n",
      "Tomato__Tomato_mosaic_virus: 373 images\n",
      "Tomato_Late_blight: 1909 images\n",
      "Tomato__Tomato_YellowLeaf__Curl_Virus: 3209 images\n",
      "Tomato__Target_Spot: 1404 images\n",
      "Potato___healthy: 152 images\n",
      "Tomato_Septoria_leaf_spot: 1771 images\n",
      "Tomato_Early_blight: 1000 images\n",
      "Potato___Late_blight: 1000 images\n",
      "Tomato_healthy: 1591 images\n",
      "Tomato_Bacterial_spot: 2127 images\n",
      "Tomato_Leaf_Mold: 952 images\n",
      "Pepper__bell___healthy: 1478 images\n",
      "Tomato_Spider_mites_Two_spotted_spider_mite: 1676 images\n",
      "Pepper__bell___Bacterial_spot: 997 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Use the Kaggle dataset path (defined in cell 2)\n",
    "base_path = dataset_path\n",
    "\n",
    "for folder in os.listdir(base_path):\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        count = len(os.listdir(folder_path))\n",
    "        print(f\"{folder}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b4f6fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ” TensorFlow Compatibility Check\n",
      "============================================================\n",
      "ğŸ Python Version: 3.10.19\n",
      "   âœ… Python version is compatible with TensorFlow\n",
      "\n",
      "ğŸ“¦ TensorFlow Check:\n",
      "   âœ… TensorFlow 2.20.0 is installed\n",
      "   âœ… TensorFlow version is compatible\n",
      "\n",
      "ğŸ–¥ï¸  Hardware Check:\n",
      "   â„¹ï¸  No GPU found - will use CPU (training will be slower)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:46:30.731775: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Python and TensorFlow Compatibility Check\n",
    "import sys\n",
    "\n",
    "def check_tensorflow_compatibility():\n",
    "    \"\"\"Check Python version and TensorFlow installation\"\"\"\n",
    "    required_major, required_minor = 3, 10\n",
    "    current_version = sys.version_info\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ” TensorFlow Compatibility Check\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check Python version\n",
    "    print(f\"ğŸ Python Version: {current_version.major}.{current_version.minor}.{current_version.micro}\")\n",
    "    \n",
    "    if current_version.major == required_major and current_version.minor >= required_minor:\n",
    "        print(\"   âœ… Python version is compatible with TensorFlow\")\n",
    "    else:\n",
    "        print(f\"   âŒ ERROR: Python {required_major}.{required_minor}.x is required!\")\n",
    "        raise RuntimeError(f\"Python {required_major}.{required_minor}.x required for TensorFlow\")\n",
    "    \n",
    "    # Check TensorFlow installation\n",
    "    print(\"\\nğŸ“¦ TensorFlow Check:\")\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        tf_version = tf.__version__\n",
    "        print(f\"   âœ… TensorFlow {tf_version} is installed\")\n",
    "        \n",
    "        # Check TensorFlow version compatibility\n",
    "        try:\n",
    "            from packaging import version\n",
    "            if version.parse(tf_version) >= version.parse(\"2.15.0\"):\n",
    "                print(\"   âœ… TensorFlow version is compatible\")\n",
    "            else:\n",
    "                print(f\"   âš ï¸  WARNING: TensorFlow 2.15.0+ recommended, found {tf_version}\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Check GPU availability\n",
    "        print(\"\\nğŸ–¥ï¸  Hardware Check:\")\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            print(f\"   âœ… Found {len(gpus)} GPU(s)\")\n",
    "            for i, gpu in enumerate(gpus):\n",
    "                print(f\"      GPU {i}: {gpu.name}\")\n",
    "        else:\n",
    "            print(\"   â„¹ï¸  No GPU found - will use CPU (training will be slower)\")\n",
    "        \n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(\"   âŒ TensorFlow is NOT installed\")\n",
    "        print(\"   ğŸ“¦ Please install TensorFlow: %pip install tensorflow>=2.15.0\")\n",
    "        return False\n",
    "\n",
    "# Run compatibility check\n",
    "tensorflow_ready = check_tensorflow_compatibility()\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not tensorflow_ready:\n",
    "    raise ImportError(\"TensorFlow is not installed. Please install it before proceeding.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf4d714",
   "metadata": {},
   "source": [
    "## Install TensorFlow (if needed)\n",
    "\n",
    "Install TensorFlow if it's not already installed. This may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69dd97fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TensorFlow 2.20.0 is already installed\n",
      "   Skipping installation.\n"
     ]
    }
   ],
   "source": [
    "# Install TensorFlow 2.15+ - Requires Python 3.10.x\n",
    "# Make sure you've run the Python version check cell above first!\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"âœ… TensorFlow {tf.__version__} is already installed\")\n",
    "    print(\"   Skipping installation.\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ TensorFlow not found. Installing TensorFlow 2.15.0...\")\n",
    "    print(\"   This may take several minutes. Please be patient...\")\n",
    "    try:\n",
    "        %pip install -q tensorflow>=2.15.0\n",
    "        import tensorflow as tf\n",
    "        print(f\"âœ… TensorFlow {tf.__version__} installed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error installing TensorFlow: {e}\")\n",
    "        print(\"   Please try installing manually: %pip install tensorflow>=2.15.0\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea925a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.19 (main, Oct 10 2025, 08:52:10) [GCC 13.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2eb68d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./venv/lib/python3.10/site-packages (25.3)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad9f289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./venv/lib/python3.10/site-packages (25.3)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (80.9.0)\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.10/site-packages (0.45.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip setuptools wheel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1662769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./venv/lib/python3.10/site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./venv/lib/python3.10/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./venv/lib/python3.10/site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./venv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./venv/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (6.33.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in ./venv/lib/python3.10/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.10/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.2.6)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./venv/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in ./venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in ./venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in ./venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in ./venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceadef89",
   "metadata": {},
   "source": [
    "Import TensorFlow and OS Modules âš¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81018f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd522d2",
   "metadata": {},
   "source": [
    "Load Plant Images as TensorFlow Datasets ğŸŒ±ğŸ–¼ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "296ca0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading plant images as TensorFlow datasets...\n",
      "   Dataset path: /home/mahmoud-matter/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage\n",
      "   Image size: (224, 224)\n",
      "   Batch size: 32\n",
      "   Validation split: 20.0%\n",
      "\n",
      "ğŸ“¥ Loading training dataset...\n",
      "Found 20638 files belonging to 15 classes.\n",
      "Using 16511 files for training.\n",
      "âœ… Training dataset loaded:\n",
      "   - Found 16511 files\n",
      "   - Number of classes: 15\n",
      "   - Classes: ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato__Target_Spot', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato__Tomato_mosaic_virus', 'Tomato_healthy']\n",
      "\n",
      "ğŸ“¥ Loading validation dataset...\n",
      "Found 20638 files belonging to 15 classes.\n",
      "Using 4127 files for validation.\n",
      "âœ… Validation dataset loaded:\n",
      "   - Found 4127 files\n",
      "âœ… Class names verified (train and validation match)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Validate dataset_path exists\n",
    "if 'dataset_path' not in globals():\n",
    "    raise NameError(\"dataset_path not defined. Please run the dataset download cell first.\")\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError(f\"Dataset path does not exist: {dataset_path}\")\n",
    "\n",
    "# Configuration\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "validation_split = 0.2\n",
    "random_seed = 42\n",
    "\n",
    "print(\"ğŸ“‚ Loading plant images as TensorFlow datasets...\")\n",
    "print(f\"   Dataset path: {dataset_path}\")\n",
    "print(f\"   Image size: {img_size}\")\n",
    "print(f\"   Batch size: {batch_size}\")\n",
    "print(f\"   Validation split: {validation_split * 100}%\")\n",
    "\n",
    "try:\n",
    "    # Load training dataset\n",
    "    print(\"\\nğŸ“¥ Loading training dataset...\")\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        dataset_path,\n",
    "        validation_split=validation_split,\n",
    "        subset=\"training\",\n",
    "        seed=random_seed,\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        label_mode='int'  # Explicit label mode\n",
    "    )\n",
    "    \n",
    "    # IMPORTANT: Save class_names BEFORE any transformations\n",
    "    class_names = train_ds.class_names\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    print(f\"âœ… Training dataset loaded:\")\n",
    "    print(f\"   - Found {len(train_ds.file_paths) if hasattr(train_ds, 'file_paths') else 'N/A'} files\")\n",
    "    print(f\"   - Number of classes: {num_classes}\")\n",
    "    print(f\"   - Classes: {class_names}\")\n",
    "    \n",
    "    # Load validation dataset\n",
    "    print(\"\\nğŸ“¥ Loading validation dataset...\")\n",
    "    val_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        dataset_path,\n",
    "        validation_split=validation_split,\n",
    "        subset=\"validation\",\n",
    "        seed=random_seed,\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        label_mode='int'  # Explicit label mode\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Validation dataset loaded:\")\n",
    "    print(f\"   - Found {len(val_test_ds.file_paths) if hasattr(val_test_ds, 'file_paths') else 'N/A'} files\")\n",
    "    \n",
    "    # Verify class names match\n",
    "    if val_test_ds.class_names != class_names:\n",
    "        print(\"âš ï¸  WARNING: Class names don't match between train and validation sets!\")\n",
    "    else:\n",
    "        print(\"âœ… Class names verified (train and validation match)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading datasets: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f3608c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69eb2dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Dataset Summary:\n",
      "   - Number of classes: 15\n",
      "   - Class names: ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato__Target_Spot', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato__Tomato_mosaic_virus', 'Tomato_healthy']\n",
      "\n",
      "âš¡ Optimizing dataset performance with prefetching...\n",
      "âœ… Datasets optimized and ready for training\n"
     ]
    }
   ],
   "source": [
    "# Optimize dataset performance with prefetching\n",
    "# NOTE: class_names and num_classes should already be saved from the previous cell\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Verify class_names and num_classes are defined\n",
    "if 'class_names' not in globals() or 'num_classes' not in globals():\n",
    "    raise NameError(\"class_names and num_classes not defined. Please run the dataset loading cell first.\")\n",
    "\n",
    "print(f\"ğŸ“Š Dataset Summary:\")\n",
    "print(f\"   - Number of classes: {num_classes}\")\n",
    "print(f\"   - Class names: {class_names}\")\n",
    "\n",
    "# Apply prefetching for better performance\n",
    "# This must be done AFTER saving class_names (which we did in the previous cell)\n",
    "print(\"\\nâš¡ Optimizing dataset performance with prefetching...\")\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_test_ds = val_test_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"âœ… Datasets optimized and ready for training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38b5c71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ï¸  Building ResNet50 Transfer Learning Model...\n",
      "   - Number of classes: 15\n",
      "   - Input shape: (224, 224, 3)\n",
      "\n",
      "ğŸ“¥ Loading pre-trained ResNet50 (ImageNet weights)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Base model loaded and frozen\n",
      "\n",
      "ğŸ”¨ Building model architecture...\n",
      "\n",
      "âš™ï¸  Compiling model...\n",
      "âœ… Model compiled successfully!\n",
      "\n",
      "ğŸ“‹ Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ rescaling           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ rescaling[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ get_item_1          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ rescaling[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ get_item_2          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ rescaling[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ stack (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Stack</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ get_item_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ stack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ resnet50            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> â”‚ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">30,735</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)        â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ rescaling           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚ (\u001b[38;5;33mRescaling\u001b[0m)         â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ get_item (\u001b[38;5;33mGetItem\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ rescaling[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ get_item_1          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ rescaling[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mGetItem\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ get_item_2          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ rescaling[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mGetItem\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ stack (\u001b[38;5;33mStack\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ get_item_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add (\u001b[38;5;33mAdd\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ stack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ resnet50            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      â”‚ \u001b[38;5;34m23,587,712\u001b[0m â”‚ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        â”‚     \u001b[38;5;34m30,735\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,618,447</span> (90.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,618,447\u001b[0m (90.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,735</span> (120.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,735\u001b[0m (120.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# Verify required variables are defined\n",
    "required_vars = ['num_classes', 'class_names', 'data_augmentation']\n",
    "missing_vars = [v for v in required_vars if v not in globals()]\n",
    "\n",
    "if missing_vars:\n",
    "    raise NameError(f\"Missing required variables: {missing_vars}. Please run previous cells first.\")\n",
    "\n",
    "print(\"ğŸ—ï¸  Building ResNet50 Transfer Learning Model...\")\n",
    "print(f\"   - Number of classes: {num_classes}\")\n",
    "print(f\"   - Input shape: (224, 224, 3)\")\n",
    "\n",
    "try:\n",
    "    # Load pre-trained ResNet50 base model\n",
    "    print(\"\\nğŸ“¥ Loading pre-trained ResNet50 (ImageNet weights)...\")\n",
    "    base_model = ResNet50(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    print(\"âœ… Base model loaded and frozen\")\n",
    "    \n",
    "    # Build the model\n",
    "    print(\"\\nğŸ”¨ Building model architecture...\")\n",
    "    inputs = layers.Input(shape=(224, 224, 3))\n",
    "    \n",
    "    # Apply data augmentation first (works on [0, 1] range)\n",
    "    x = data_augmentation(inputs)\n",
    "    \n",
    "    # Scale from [0, 1] to [0, 255] for ResNet preprocessing\n",
    "    x = layers.Rescaling(255.0)(x)\n",
    "    \n",
    "    # Apply ResNet preprocessing (normalizes to ImageNet stats)\n",
    "    x = tf.keras.applications.resnet.preprocess_input(x)\n",
    "    \n",
    "    # Pass through base model\n",
    "    x = base_model(x, training=False)\n",
    "    \n",
    "    # Add classification head\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "    model_resnet = Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    print(\"\\nâš™ï¸  Compiling model...\")\n",
    "    model_resnet.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Model compiled successfully!\")\n",
    "    print(\"\\nğŸ“‹ Model Summary:\")\n",
    "    model_resnet.summary()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error building model: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b8ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m120/516\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m10:40\u001b[0m 2s/step - accuracy: 0.1054 - loss: 635.9990"
     ]
    }
   ],
   "source": [
    "history_resnet = model_resnet.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_test_ds,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd82e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "models_dir = \"models\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    print(f\"ğŸ“ Created directory: {models_dir}\")\n",
    "\n",
    "# Save the model\n",
    "model_path = os.path.join(models_dir, \"resnet50.h5\")\n",
    "\n",
    "try:\n",
    "    if 'model_resnet' not in globals():\n",
    "        raise NameError(\"model_resnet not defined. Please train the model first.\")\n",
    "    \n",
    "    print(f\"ğŸ’¾ Saving model to: {model_path}\")\n",
    "    model_resnet.save(model_path)\n",
    "    print(\"âœ… Model saved successfully!\")\n",
    "    \n",
    "    # Verify the file was created\n",
    "    if os.path.exists(model_path):\n",
    "        file_size = os.path.getsize(model_path) / (1024 * 1024)  # Size in MB\n",
    "        print(f\"   File size: {file_size:.2f} MB\")\n",
    "    else:\n",
    "        print(\"âš ï¸  WARNING: Model file not found after saving!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error saving model: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9daf8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"changes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
