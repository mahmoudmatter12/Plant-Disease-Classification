{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ae81844a",
      "metadata": {
        "id": "ae81844a"
      },
      "source": [
        "# Plant Disease Classification with ResNet50\n",
        "\n",
        "This notebook demonstrates plant disease classification using transfer learning with ResNet50.\n",
        "\n",
        "## Prerequisites\n",
        "- Python 3.10.x\n",
        "- Virtual environment (recommended)\n",
        "- Internet connection for downloading dataset and models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "886b9da1",
      "metadata": {
        "id": "886b9da1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Comprehensive Dependency Checker\n",
        "This cell checks all required dependencies before proceeding.\n",
        "Run this cell first to ensure your environment is properly configured.\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import importlib\n",
        "\n",
        "# Try to import packaging for version comparison\n",
        "try:\n",
        "    from packaging import version\n",
        "    HAS_PACKAGING = True\n",
        "except ImportError:\n",
        "    HAS_PACKAGING = False\n",
        "    print(\"‚ö†Ô∏è  Note: 'packaging' module not available - version checking will be limited\")\n",
        "\n",
        "def check_python_version():\n",
        "    \"\"\"Check if Python version is compatible\"\"\"\n",
        "    required_major, required_minor = 3, 10\n",
        "    current_version = sys.version_info\n",
        "    is_compatible = (current_version.major == required_major and\n",
        "                    current_version.minor >= required_minor)\n",
        "\n",
        "    print(f\"üêç Python Version Check\")\n",
        "    print(f\"   Current: {current_version.major}.{current_version.minor}.{current_version.micro}\")\n",
        "    print(f\"   Required: {required_major}.{required_minor}.x\")\n",
        "\n",
        "    if is_compatible:\n",
        "        print(\"   ‚úÖ Python version is compatible!\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå ERROR: Python {required_major}.{required_minor}.x is required!\")\n",
        "        raise RuntimeError(f\"Python {required_major}.{required_minor}.x required, got {current_version.major}.{current_version.minor}\")\n",
        "\n",
        "    return is_compatible\n",
        "\n",
        "def check_package(package_name, min_version=None, import_name=None):\n",
        "    \"\"\"Check if a package is installed and optionally verify version\"\"\"\n",
        "    import_name = import_name or package_name\n",
        "    try:\n",
        "        module = importlib.import_module(import_name)\n",
        "        installed_version = getattr(module, '__version__', 'unknown')\n",
        "\n",
        "        if min_version and installed_version != 'unknown' and HAS_PACKAGING:\n",
        "            try:\n",
        "                if version.parse(installed_version) < version.parse(min_version):\n",
        "                    print(f\"   ‚ö†Ô∏è  {package_name}: {installed_version} (requires >= {min_version})\")\n",
        "                    return False\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        print(f\"   ‚úÖ {package_name}: {installed_version}\")\n",
        "        return True\n",
        "    except ImportError:\n",
        "        print(f\"   ‚ùå {package_name}: NOT INSTALLED\")\n",
        "        return False\n",
        "\n",
        "def install_package(package_spec):\n",
        "    \"\"\"Install a package using pip\"\"\"\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_spec],\n",
        "                            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# Main dependency check\n",
        "print(\"=\" * 60)\n",
        "print(\"üîç COMPREHENSIVE DEPENDENCY CHECK\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check Python version\n",
        "check_python_version()\n",
        "print()\n",
        "\n",
        "# Check core dependencies\n",
        "print(\"üì¶ Core Dependencies:\")\n",
        "dependencies = {\n",
        "    'kagglehub': None,\n",
        "    'numpy': '1.23.5',\n",
        "    'tensorflow': '2.15.0',\n",
        "    'PIL': None,  # Pillow\n",
        "}\n",
        "\n",
        "missing_packages = []\n",
        "for pkg, min_ver in dependencies.items():\n",
        "    if not check_package(pkg, min_ver):\n",
        "        missing_packages.append(pkg)\n",
        "\n",
        "print()\n",
        "\n",
        "# Check optional dependencies\n",
        "print(\"üì¶ Optional Dependencies:\")\n",
        "optional_deps = ['matplotlib', 'seaborn']\n",
        "for pkg in optional_deps:\n",
        "    check_package(pkg)\n",
        "\n",
        "print()\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if missing_packages:\n",
        "    print(f\"‚ö†Ô∏è  Missing packages: {', '.join(missing_packages)}\")\n",
        "    print(\"   Please install them using: %pip install <package_name>\")\n",
        "    print(\"   Or install all requirements: %pip install -r requirements.txt\")\n",
        "else:\n",
        "    print(\"‚úÖ All required dependencies are installed!\")\n",
        "    print(\"   You can proceed to the next cell.\")\n",
        "\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12814c73",
      "metadata": {
        "id": "12814c73"
      },
      "source": [
        "## Install and Import KaggleHub\n",
        "\n",
        "Install kagglehub if not already installed, then download the plant disease dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e644ebe3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e644ebe3",
        "outputId": "c3e584d1-c835-404d-d76f-838f35f0e57e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ kagglehub is already installed\n"
          ]
        }
      ],
      "source": [
        "# Install kagglehub if not already installed\n",
        "try:\n",
        "    import kagglehub\n",
        "    print(\"‚úÖ kagglehub is already installed\")\n",
        "except ImportError:\n",
        "    print(\"üì¶ Installing kagglehub...\")\n",
        "    %pip install -q kagglehub\n",
        "    import kagglehub\n",
        "    print(\"‚úÖ kagglehub installed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7fc184d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fc184d5",
        "outputId": "1ef2008a-ac44-4529-ddee-93a7241c2430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Downloading plant disease dataset from Kaggle...\n",
            "Using Colab cache for faster access to the 'plantdisease' dataset.\n",
            "‚úÖ Dataset downloaded to: /kaggle/input/plantdisease\n",
            "‚úÖ Found PlantVillage folder: /kaggle/input/plantdisease/PlantVillage\n",
            "üìä Found 15 class folders\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # Download latest version\n",
        "    print(\"üì• Downloading plant disease dataset from Kaggle...\")\n",
        "    kaggle_path = kagglehub.dataset_download(\"emmarex/plantdisease\")\n",
        "    print(f\"‚úÖ Dataset downloaded to: {kaggle_path}\")\n",
        "\n",
        "    # Find the PlantVillage folder within the Kaggle dataset\n",
        "    # The dataset might have the PlantVillage folder directly or inside a subfolder\n",
        "    dataset_path = None\n",
        "\n",
        "    # Check common locations\n",
        "    possible_paths = [\n",
        "        os.path.join(kaggle_path, \"PlantVillage\"),\n",
        "        os.path.join(kaggle_path, \"archive\", \"PlantVillage\"),\n",
        "        kaggle_path\n",
        "    ]\n",
        "\n",
        "    for path in possible_paths:\n",
        "        if os.path.exists(path) and os.path.isdir(path):\n",
        "            # Check if this looks like the PlantVillage folder (has subdirectories)\n",
        "            subdirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
        "            if len(subdirs) > 5:  # PlantVillage should have many class folders\n",
        "                dataset_path = path\n",
        "                break\n",
        "\n",
        "    # If not found, search recursively\n",
        "    if dataset_path is None:\n",
        "        print(\"üîç Searching for PlantVillage folder...\")\n",
        "        for root, dirs, files in os.walk(kaggle_path):\n",
        "            if \"PlantVillage\" in dirs:\n",
        "                candidate = os.path.join(root, \"PlantVillage\")\n",
        "                if os.path.isdir(candidate):\n",
        "                    subdirs = [d for d in os.listdir(candidate) if os.path.isdir(os.path.join(candidate, d))]\n",
        "                    if len(subdirs) > 5:\n",
        "                        dataset_path = candidate\n",
        "                        break\n",
        "\n",
        "    if dataset_path is None:\n",
        "        raise FileNotFoundError(\"Could not find PlantVillage folder in the downloaded dataset\")\n",
        "\n",
        "    # Validate dataset path\n",
        "    if not os.path.exists(dataset_path):\n",
        "        raise FileNotFoundError(f\"Dataset path does not exist: {dataset_path}\")\n",
        "\n",
        "    if not os.path.isdir(dataset_path):\n",
        "        raise NotADirectoryError(f\"Dataset path is not a directory: {dataset_path}\")\n",
        "\n",
        "    print(f\"‚úÖ Found PlantVillage folder: {dataset_path}\")\n",
        "\n",
        "    # Count classes to verify dataset\n",
        "    class_folders = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
        "    print(f\"üìä Found {len(class_folders)} class folders\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error downloading or locating dataset: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c17187ea",
      "metadata": {
        "id": "c17187ea"
      },
      "source": [
        "## Extract ZIP File (if needed)\n",
        "\n",
        "Check if the dataset needs to be extracted from a ZIP file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fc92c3ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc92c3ba",
        "outputId": "1de9d2e1-4b30-4642-9966-ffb26f08d173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ No zip files found - dataset is already extracted from Kaggle\n",
            "‚úÖ Using dataset path: /kaggle/input/plantdisease/PlantVillage\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # Check if we need to extract a zip file from the Kaggle dataset\n",
        "    # Kaggle usually extracts automatically, but let's check for zip files\n",
        "    if 'kaggle_path' not in globals():\n",
        "        raise NameError(\"kaggle_path not defined. Please run the previous cell first.\")\n",
        "\n",
        "    if not os.path.exists(kaggle_path):\n",
        "        raise FileNotFoundError(f\"Kaggle path does not exist: {kaggle_path}\")\n",
        "\n",
        "    zip_files = [f for f in os.listdir(kaggle_path) if f.endswith('.zip')]\n",
        "\n",
        "    if zip_files:\n",
        "        print(f\"üì¶ Found zip file(s): {zip_files}\")\n",
        "        zip_path = os.path.join(kaggle_path, zip_files[0])\n",
        "\n",
        "        if not os.path.exists(zip_path):\n",
        "            raise FileNotFoundError(f\"Zip file not found: {zip_path}\")\n",
        "\n",
        "        extract_path = kaggle_path\n",
        "        print(f\"üìÇ Extracting {zip_files[0]}...\")\n",
        "\n",
        "        try:\n",
        "            with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "                z.extractall(extract_path)\n",
        "            print(\"‚úÖ Zip file extracted successfully!\")\n",
        "        except zipfile.BadZipFile:\n",
        "            raise ValueError(f\"Invalid zip file: {zip_path}\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error extracting zip file: {e}\")\n",
        "\n",
        "        # Re-find PlantVillage after extraction\n",
        "        print(\"üîç Re-locating PlantVillage folder...\")\n",
        "        for root, dirs, files in os.walk(kaggle_path):\n",
        "            if \"PlantVillage\" in dirs:\n",
        "                candidate = os.path.join(root, \"PlantVillage\")\n",
        "                if os.path.isdir(candidate):\n",
        "                    dataset_path = candidate\n",
        "                    break\n",
        "\n",
        "        if 'dataset_path' in locals() and dataset_path:\n",
        "            print(f\"‚úÖ Updated dataset path: {dataset_path}\")\n",
        "        else:\n",
        "            raise FileNotFoundError(\"Could not find PlantVillage folder after extraction\")\n",
        "    else:\n",
        "        print(\"‚úÖ No zip files found - dataset is already extracted from Kaggle\")\n",
        "        if 'dataset_path' in globals():\n",
        "            print(f\"‚úÖ Using dataset path: {dataset_path}\")\n",
        "        else:\n",
        "            raise NameError(\"dataset_path not defined. Please run the previous cell first.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error in zip extraction: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c400ebe",
      "metadata": {
        "id": "6c400ebe"
      },
      "source": [
        "List Files in a Folder üìÇ\n",
        "\n",
        "Quickly see all files in a directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3e996a18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e996a18",
        "outputId": "8045bf0b-cd7d-4648-ed26-d51cd50ae7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pepper__bell___Bacterial_spot', 'Potato___healthy', 'Tomato_Leaf_Mold', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato_Bacterial_spot', 'Tomato_Septoria_leaf_spot', 'Tomato_healthy', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato_Early_blight', 'Tomato__Target_Spot', 'Pepper__bell___healthy', 'Potato___Late_blight', 'Tomato_Late_blight', 'Potato___Early_blight', 'Tomato__Tomato_mosaic_virus']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Use the Kaggle dataset path (defined in cell 2)\n",
        "print(os.listdir(dataset_path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "803c60e0",
      "metadata": {
        "id": "803c60e0"
      },
      "source": [
        " Explore Folder Structure in Python üìÇ\n",
        "\n",
        "Print folder paths and a few files inside each folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "82ab8c73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82ab8c73",
        "outputId": "87094067-a5e8-4687-f172-3f67fec168f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Pepper__bell___Bacterial_spot\n",
            "   - 0f72db9c-d635-4415-9781-68937328aed2___NREC_B.Spot 9188.JPG\n",
            "   - 1b8d3e98-43d9-441d-93ef-a359e6e9ddc2___NREC_B.Spot 9052.JPG\n",
            "   - b6d35d21-4812-4e32-ab9a-b6ddda8cbb79___JR_B.Spot 8972.JPG\n",
            "   - e4e7e5a2-5aa1-4378-833d-9142358c7c9b___JR_B.Spot 9092.JPG\n",
            "   - 8b50f2db-cbf2-4758-bea6-a011f0cc1497___JR_B.Spot 3235.JPG\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Potato___healthy\n",
            "   - 7948ada9-eabc-4cb7-a579-b73e938eb716___RS_HL 4185.JPG\n",
            "   - f5bd2732-197b-4d8e-bb50-a4966dc416f5___RS_HL 1840.JPG\n",
            "   - 5a3fc4bb-a78c-4276-8934-f0b037ffb860___RS_HL 5412.JPG\n",
            "   - 875d6ded-5f01-495c-a945-ad2e17f87f91___RS_HL 1848.JPG\n",
            "   - 4ae82355-6885-40e7-9807-dabe46ed3441___RS_HL 5410.JPG\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Tomato_Leaf_Mold\n",
            "   - 74cb417c-24ca-43b2-897a-8c310636ac22___Crnl_L.Mold 7149.JPG\n",
            "   - 05205449-e0d0-4d2f-a2fb-6f1fc0e2e9c5___Crnl_L.Mold 8717.JPG\n",
            "   - 16cf47c0-abb4-47e3-bab3-4a7c6348b7ab___Crnl_L.Mold 6995.JPG\n",
            "   - 82567342-f689-4e61-ac38-b25db55bb684___Crnl_L.Mold 7128.JPG\n",
            "   - 662d31b7-5dcb-4af1-b645-20b83610d1ee___Crnl_L.Mold 8687.JPG\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Tomato__Tomato_YellowLeaf__Curl_Virus\n",
            "   - 0ce66ec5-0bb7-4fde-9c61-750a1a150f75___UF.GRC_YLCV_Lab 02219.JPG\n",
            "   - 8ef3ea77-0818-48e5-a8fa-3b34f963e85e___UF.GRC_YLCV_Lab 03131.JPG\n",
            "   - 0a1d1def-462c-46d3-90e6-2a11fcb45a21___UF.GRC_YLCV_Lab 01675.JPG\n",
            "   - 465282eb-a2ff-4663-be80-1a47e92afb84___UF.GRC_YLCV_Lab 03330.JPG\n",
            "   - 292880f6-581b-43c3-9093-da727e219c1a___UF.GRC_YLCV_Lab 02129.JPG\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Tomato_Bacterial_spot\n",
            "   - a129e8eb-e2b4-4a8a-a509-f6625da6b11c___GCREC_Bact.Sp 3002.JPG\n",
            "   - 21833eb1-b84e-4471-816b-166e575ed0e7___GCREC_Bact.Sp 3244.JPG\n",
            "   - 67c8bbdb-ba79-4c64-897f-e9052728df45___GCREC_Bact.Sp 3008.JPG\n",
            "   - 79d8d47a-c8c9-450d-a567-d096b307c532___GCREC_Bact.Sp 2973.JPG\n",
            "   - 4436edf6-8c6d-4cc5-b973-1f0afd218e86___GCREC_Bact.Sp 6271.JPG\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Tomato_Septoria_leaf_spot\n",
            "   - 8854cb53-e283-46b4-b150-3d0b414b77fd___Matt.S_CG 0951.JPG\n",
            "   - 2ff033e7-73ea-49aa-b81a-164963cc464d___Matt.S_CG 6638.JPG\n",
            "   - 13bc2fc9-24ab-44c5-bf5d-ea0d1a68798f___Matt.S_CG 0980.JPG\n",
            "   - 87ba14ab-3b74-407b-977e-237258eb6947___Matt.S_CG 6787.JPG\n",
            "   - 87e254da-f3ea-4127-9a08-ed12180da6de___Matt.S_CG 6334.JPG\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Tomato_healthy\n",
            "   - 4a1e2b71-992a-4a64-a599-b49b8fa75378___RS_HL 0627.JPG\n",
            "   - 7890f4dc-0c55-454b-ab23-3b25d3d973c4___GH_HL Leaf 366.1.JPG\n",
            "   - beb8ecc5-3283-430e-b598-343f6754a752___GH_HL Leaf 328.JPG\n",
            "   - 64b5d77e-2b06-461d-94f9-5f15250a7e77___GH_HL Leaf 505.1.JPG\n",
            "   - df35d1fb-978c-4aeb-9d6f-e7da242c81b8___RS_HL 0515.JPG\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Tomato_Spider_mites_Two_spotted_spider_mite\n",
            "   - 0ade19e4-c48b-4e58-bddf-153d44d48c3e___Com.G_SpM_FL 9449.JPG\n",
            "   - ff0f33d2-9e9f-4b74-861d-a7e0fdf8d248___Com.G_SpM_FL 8511.JPG\n",
            "   - 38be0c62-a8ce-49db-8187-294abc382ad6___Com.G_SpM_FL 8895.JPG\n",
            "   - fb4d0983-9df9-40be-8b1c-bbd5b9aa3620___Com.G_SpM_FL 1770.JPG\n",
            "   - 0f94b000-c54f-45c1-b976-22cb57dda0c4___Com.G_SpM_FL 9640.JPG\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Tomato_Early_blight\n",
            "   - cf8c6e28-201c-4c8e-994f-8dcf98362e64___RS_Erly.B 7651.JPG\n",
            "   - a3d07302-420d-4b4e-94f2-6694ef9d2088___RS_Erly.B 7652.JPG\n",
            "   - e11ee1f8-8de2-4d9c-a0c1-86bc42350fd9___RS_Erly.B 9472.JPG\n",
            "   - e94d68c8-f185-4b3d-9b44-ad12e3dc891d___RS_Erly.B 9598.JPG\n",
            "   - 99cfe9bb-77a1-4bd6-9c48-58fffac2a133___RS_Erly.B 7387.JPG\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Tomato__Target_Spot\n",
            "   - d9d2d7ca-3301-4174-aec5-b4578682b0d9___Com.G_TgS_FL 8181.JPG\n",
            "   - 3ae3232f-14a1-44f4-8215-2cd9b391d271___Com.G_TgS_FL 9775.JPG\n",
            "   - 6362e569-bbfc-4315-8c1e-9becbf57b426___Com.G_TgS_FL 0830.JPG\n",
            "   - 42920fd3-0a32-42c8-9341-4d0659cb9e7b___Com.G_TgS_FL 0967.JPG\n",
            "   - 9a6b79a4-64a9-4238-ba09-31d3312c785e___Com.G_TgS_FL 7943.JPG\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Pepper__bell___healthy\n",
            "   - b555e97b-a736-41c1-ab8f-43cadf71ae81___JR_HL 8000.JPG\n",
            "   - dcbbd3f6-1854-45fd-abac-bc77a4e46e4e___JR_HL 7803.JPG\n",
            "   - fb916ecd-183f-4caa-8daf-fb9d83f43e88___JR_HL 7972.JPG\n",
            "   - 8a3c1599-aee5-477c-b693-e1ccd68343c4___JR_HL 8644.JPG\n",
            "   - 85bf3b78-72e9-4e2a-8f7c-b330b36170ab___JR_HL 5981.JPG\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Potato___Late_blight\n",
            "   - 5f0801e0-b127-4596-9f82-eb36f8ee5c85___RS_LB 3852.JPG\n",
            "   - 68decf28-de55-477f-9435-56cda245a7ca___RS_LB 3195.JPG\n",
            "   - 63ec8c33-368c-433d-8953-f28f30e5985f___RS_LB 2943.JPG\n",
            "   - 6033f0b2-48e7-411c-a39b-86297f412c19___RS_LB 4020.JPG\n",
            "   - 66473aff-3438-4a8c-8c05-5fed8a4255ae___RS_LB 4473.JPG\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Tomato_Late_blight\n",
            "   - 781e93a9-2059-42de-8075-658033a6abf7___RS_Late.B 6075.JPG\n",
            "   - 283ff0be-6e5e-4b4e-bf21-639780b77ffc___GHLB2 Leaf 8636.JPG\n",
            "   - 0db85707-41f9-42df-ba3b-842d14f00a68___GHLB2 Leaf 8909.JPG\n",
            "   - 078a999d-6e6f-427e-a1e6-80b4d2df2bae___GHLB2 Leaf 9029.JPG\n",
            "   - 3dcee9ed-43bb-45a9-8cff-641b3dd62179___RS_Late.B 5324.JPG\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Potato___Early_blight\n",
            "   - ac6c3aea-ad58-4b46-b0d2-195dba86e0f6___RS_Early.B 7926.JPG\n",
            "   - 8ce2ee77-109f-4a08-bee9-2877c2201056___RS_Early.B 6834.JPG\n",
            "   - 9fa151cd-43d7-42e1-9235-72f58c584a4b___RS_Early.B 8581.JPG\n",
            "   - 212c3c65-e30e-496f-ab5e-c2f4b0446d8f___RS_Early.B 8195.JPG\n",
            "   - b83aea19-9485-412f-808d-c0a590d75388___RS_Early.B 6951.JPG\n",
            "---------------\n",
            "üìÅ Folder: /kaggle/input/plantdisease/PlantVillage/Tomato__Tomato_mosaic_virus\n",
            "   - 14c21616-aa9e-4d85-8aff-bdf7f4cf3720___PSU_CG 2079.JPG\n",
            "   - 9586aed6-53c5-4245-8994-a60ac12e422c___PSU_CG 2361.JPG\n",
            "   - dd1161b0-ed4e-42f0-a63b-1ff8d9adf3ed___PSU_CG 2405.JPG\n",
            "   - d636946f-b3da-4b36-aeb6-f602ef86a245___PSU_CG 2101.JPG\n",
            "   - 9fb02b86-77fe-450a-a85e-276cf7d1c1fb___PSU_CG 2376.JPG\n",
            "---------------\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Use the Kaggle dataset path (defined in cell 2)\n",
        "root = dataset_path\n",
        "\n",
        "for path, dirs, files in os.walk(root):\n",
        "    print(f\"üìÅ Folder: {path}\")\n",
        "    for f in files[:5]:\n",
        "        print(\"   -\", f)\n",
        "    print(\"---------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3aee2de",
      "metadata": {
        "id": "b3aee2de"
      },
      "source": [
        "Count Images in Each Class Folder üñºÔ∏è\n",
        "\n",
        "Check how many images are in each subfolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0cc79feb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cc79feb",
        "outputId": "c7cf1480-f048-46c6-accb-6ea2c276c183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pepper__bell___Bacterial_spot: 997 images\n",
            "Potato___healthy: 152 images\n",
            "Tomato_Leaf_Mold: 952 images\n",
            "Tomato__Tomato_YellowLeaf__Curl_Virus: 3209 images\n",
            "Tomato_Bacterial_spot: 2127 images\n",
            "Tomato_Septoria_leaf_spot: 1771 images\n",
            "Tomato_healthy: 1591 images\n",
            "Tomato_Spider_mites_Two_spotted_spider_mite: 1676 images\n",
            "Tomato_Early_blight: 1000 images\n",
            "Tomato__Target_Spot: 1404 images\n",
            "Pepper__bell___healthy: 1478 images\n",
            "Potato___Late_blight: 1000 images\n",
            "Tomato_Late_blight: 1909 images\n",
            "Potato___Early_blight: 1000 images\n",
            "Tomato__Tomato_mosaic_virus: 373 images\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Use the Kaggle dataset path (defined in cell 2)\n",
        "base_path = dataset_path\n",
        "\n",
        "for folder in os.listdir(base_path):\n",
        "    folder_path = os.path.join(base_path, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        count = len(os.listdir(folder_path))\n",
        "        print(f\"{folder}: {count} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2b4f6fd5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b4f6fd5",
        "outputId": "d6e07601-b9cf-48fd-ad71-521cbdea63a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üîç TensorFlow Compatibility Check\n",
            "============================================================\n",
            "üêç Python Version: 3.12.12\n",
            "   ‚úÖ Python version is compatible with TensorFlow\n",
            "\n",
            "üì¶ TensorFlow Check:\n",
            "   ‚úÖ TensorFlow 2.19.0 is installed\n",
            "   ‚úÖ TensorFlow version is compatible\n",
            "\n",
            "üñ•Ô∏è  Hardware Check:\n",
            "   ‚ÑπÔ∏è  No GPU found - will use CPU (training will be slower)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Enhanced Python and TensorFlow Compatibility Check\n",
        "import sys\n",
        "\n",
        "def check_tensorflow_compatibility():\n",
        "    \"\"\"Check Python version and TensorFlow installation\"\"\"\n",
        "    required_major, required_minor = 3, 10\n",
        "    current_version = sys.version_info\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üîç TensorFlow Compatibility Check\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Check Python version\n",
        "    print(f\"üêç Python Version: {current_version.major}.{current_version.minor}.{current_version.micro}\")\n",
        "\n",
        "    if current_version.major == required_major and current_version.minor >= required_minor:\n",
        "        print(\"   ‚úÖ Python version is compatible with TensorFlow\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå ERROR: Python {required_major}.{required_minor}.x is required!\")\n",
        "        raise RuntimeError(f\"Python {required_major}.{required_minor}.x required for TensorFlow\")\n",
        "\n",
        "    # Check TensorFlow installation\n",
        "    print(\"\\nüì¶ TensorFlow Check:\")\n",
        "    try:\n",
        "        import tensorflow as tf\n",
        "        tf_version = tf.__version__\n",
        "        print(f\"   ‚úÖ TensorFlow {tf_version} is installed\")\n",
        "\n",
        "        # Check TensorFlow version compatibility\n",
        "        try:\n",
        "            from packaging import version\n",
        "            if version.parse(tf_version) >= version.parse(\"2.15.0\"):\n",
        "                print(\"   ‚úÖ TensorFlow version is compatible\")\n",
        "            else:\n",
        "                print(f\"   ‚ö†Ô∏è  WARNING: TensorFlow 2.15.0+ recommended, found {tf_version}\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Check GPU availability\n",
        "        print(\"\\nüñ•Ô∏è  Hardware Check:\")\n",
        "        gpus = tf.config.list_physical_devices('GPU')\n",
        "        if gpus:\n",
        "            print(f\"   ‚úÖ Found {len(gpus)} GPU(s)\")\n",
        "            for i, gpu in enumerate(gpus):\n",
        "                print(f\"      GPU {i}: {gpu.name}\")\n",
        "        else:\n",
        "            print(\"   ‚ÑπÔ∏è  No GPU found - will use CPU (training will be slower)\")\n",
        "\n",
        "        return True\n",
        "    except ImportError:\n",
        "        print(\"   ‚ùå TensorFlow is NOT installed\")\n",
        "        print(\"   üì¶ Please install TensorFlow: %pip install tensorflow>=2.15.0\")\n",
        "        return False\n",
        "\n",
        "# Run compatibility check\n",
        "tensorflow_ready = check_tensorflow_compatibility()\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if not tensorflow_ready:\n",
        "    raise ImportError(\"TensorFlow is not installed. Please install it before proceeding.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbf4d714",
      "metadata": {
        "id": "fbf4d714"
      },
      "source": [
        "## Install TensorFlow (if needed)\n",
        "\n",
        "Install TensorFlow if it's not already installed. This may take several minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "69dd97fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69dd97fd",
        "outputId": "8e49f280-fa99-43c4-d419-671b07c470c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ TensorFlow 2.19.0 is already installed\n",
            "   Skipping installation.\n"
          ]
        }
      ],
      "source": [
        "# Install TensorFlow 2.15+ - Requires Python 3.10.x\n",
        "# Make sure you've run the Python version check cell above first!\n",
        "\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    print(f\"‚úÖ TensorFlow {tf.__version__} is already installed\")\n",
        "    print(\"   Skipping installation.\")\n",
        "except ImportError:\n",
        "    print(\"üì¶ TensorFlow not found. Installing TensorFlow 2.15.0...\")\n",
        "    print(\"   This may take several minutes. Please be patient...\")\n",
        "    try:\n",
        "        %pip install -q tensorflow>=2.15.0\n",
        "        import tensorflow as tf\n",
        "        print(f\"‚úÖ TensorFlow {tf.__version__} installed successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error installing TensorFlow: {e}\")\n",
        "        print(\"   Please try installing manually: %pip install tensorflow>=2.15.0\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9ea925a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ea925a8",
        "outputId": "746597ec-d348-4c18-b6ec-86d36991be07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2eb68d6",
      "metadata": {
        "id": "e2eb68d6",
        "outputId": "d33d45fe-f7a1-4453-d4c9-64c8cec03e4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in ./venv/lib/python3.10/site-packages (25.3)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install --upgrade pip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad9f289c",
      "metadata": {
        "id": "ad9f289c",
        "outputId": "4f8e9457-2d94-4970-d46b-e793a373fdde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in ./venv/lib/python3.10/site-packages (25.3)\n",
            "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (80.9.0)\n",
            "Requirement already satisfied: wheel in ./venv/lib/python3.10/site-packages (0.45.1)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install --upgrade pip setuptools wheel\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1662769e",
      "metadata": {
        "id": "1662769e",
        "outputId": "38555f83-a879-4d76-b759-18c6d4b39923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in ./venv/lib/python3.10/site-packages (2.20.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in ./venv/lib/python3.10/site-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./venv/lib/python3.10/site-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in ./venv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in ./venv/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (6.33.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.32.5)\n",
            "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from tensorflow) (80.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in ./venv/lib/python3.10/site-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.10/site-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (3.12.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.2.6)\n",
            "Requirement already satisfied: h5py>=3.11.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./venv/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: pillow in ./venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in ./venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
            "Requirement already satisfied: namex in ./venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in ./venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in ./venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceadef89",
      "metadata": {
        "id": "ceadef89"
      },
      "source": [
        "Import TensorFlow and OS Modules ‚ö°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "81018f2f",
      "metadata": {
        "id": "81018f2f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dd522d2",
      "metadata": {
        "id": "5dd522d2"
      },
      "source": [
        "Load Plant Images as TensorFlow Datasets üå±üñºÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "296ca0ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "296ca0ff",
        "outputId": "aca6d3c3-3bab-4d2b-cd2a-f4c51edaa5c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Loading plant images as TensorFlow datasets...\n",
            "   Dataset path: /kaggle/input/plantdisease/PlantVillage\n",
            "   Image size: (224, 224)\n",
            "   Batch size: 32\n",
            "   Validation split: 20.0%\n",
            "\n",
            "üì• Loading training dataset...\n",
            "Found 20638 files belonging to 15 classes.\n",
            "Using 16511 files for training.\n",
            "‚úÖ Training dataset loaded:\n",
            "   - Found 16511 files\n",
            "   - Number of classes: 15\n",
            "   - Classes: ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato__Target_Spot', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato__Tomato_mosaic_virus', 'Tomato_healthy']\n",
            "\n",
            "üì• Loading validation dataset...\n",
            "Found 20638 files belonging to 15 classes.\n",
            "Using 4127 files for validation.\n",
            "‚úÖ Validation dataset loaded:\n",
            "   - Found 4127 files\n",
            "‚úÖ Class names verified (train and validation match)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Validate dataset_path exists\n",
        "if 'dataset_path' not in globals():\n",
        "    raise NameError(\"dataset_path not defined. Please run the dataset download cell first.\")\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    raise FileNotFoundError(f\"Dataset path does not exist: {dataset_path}\")\n",
        "\n",
        "# Configuration\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "validation_split = 0.2\n",
        "random_seed = 42\n",
        "\n",
        "print(\"üìÇ Loading plant images as TensorFlow datasets...\")\n",
        "print(f\"   Dataset path: {dataset_path}\")\n",
        "print(f\"   Image size: {img_size}\")\n",
        "print(f\"   Batch size: {batch_size}\")\n",
        "print(f\"   Validation split: {validation_split * 100}%\")\n",
        "\n",
        "try:\n",
        "    # Load training dataset\n",
        "    print(\"\\nüì• Loading training dataset...\")\n",
        "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        dataset_path,\n",
        "        validation_split=validation_split,\n",
        "        subset=\"training\",\n",
        "        seed=random_seed,\n",
        "        image_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        label_mode='int'  # Explicit label mode\n",
        "    )\n",
        "\n",
        "    # IMPORTANT: Save class_names BEFORE any transformations\n",
        "    class_names = train_ds.class_names\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    print(f\"‚úÖ Training dataset loaded:\")\n",
        "    print(f\"   - Found {len(train_ds.file_paths) if hasattr(train_ds, 'file_paths') else 'N/A'} files\")\n",
        "    print(f\"   - Number of classes: {num_classes}\")\n",
        "    print(f\"   - Classes: {class_names}\")\n",
        "\n",
        "    # Load validation dataset\n",
        "    print(\"\\nüì• Loading validation dataset...\")\n",
        "    val_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        dataset_path,\n",
        "        validation_split=validation_split,\n",
        "        subset=\"validation\",\n",
        "        seed=random_seed,\n",
        "        image_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        label_mode='int'  # Explicit label mode\n",
        "    )\n",
        "\n",
        "    print(f\"‚úÖ Validation dataset loaded:\")\n",
        "    print(f\"   - Found {len(val_test_ds.file_paths) if hasattr(val_test_ds, 'file_paths') else 'N/A'} files\")\n",
        "\n",
        "    # Verify class names match\n",
        "    if val_test_ds.class_names != class_names:\n",
        "        print(\"‚ö†Ô∏è  WARNING: Class names don't match between train and validation sets!\")\n",
        "    else:\n",
        "        print(\"‚úÖ Class names verified (train and validation match)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading datasets: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2f3608c3",
      "metadata": {
        "id": "2f3608c3"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.1),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "69eb2dee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69eb2dee",
        "outputId": "89fe5ae4-b65e-43de-f5ad-355613b5f92e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Dataset Summary:\n",
            "   - Number of classes: 15\n",
            "   - Class names: ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato__Target_Spot', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato__Tomato_mosaic_virus', 'Tomato_healthy']\n",
            "\n",
            "‚ö° Optimizing dataset performance with prefetching...\n",
            "‚úÖ Datasets optimized and ready for training\n"
          ]
        }
      ],
      "source": [
        "# Optimize dataset performance with prefetching\n",
        "# NOTE: class_names and num_classes should already be saved from the previous cell\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Verify class_names and num_classes are defined\n",
        "if 'class_names' not in globals() or 'num_classes' not in globals():\n",
        "    raise NameError(\"class_names and num_classes not defined. Please run the dataset loading cell first.\")\n",
        "\n",
        "print(f\"üìä Dataset Summary:\")\n",
        "print(f\"   - Number of classes: {num_classes}\")\n",
        "print(f\"   - Class names: {class_names}\")\n",
        "\n",
        "# Apply prefetching for better performance\n",
        "# This must be done AFTER saving class_names (which we did in the previous cell)\n",
        "print(\"\\n‚ö° Optimizing dataset performance with prefetching...\")\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_test_ds = val_test_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print(\"‚úÖ Datasets optimized and ready for training\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "38b5c71b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "38b5c71b",
        "outputId": "a1ae1404-bcc8-45be-a359-a13781fdfc0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèóÔ∏è  Building ResNet50 Transfer Learning Model...\n",
            "   - Number of classes: 15\n",
            "   - Input shape: (224, 224, 3)\n",
            "\n",
            "üì• Loading pre-trained ResNet50 (ImageNet weights)...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "‚úÖ Base model loaded and frozen\n",
            "\n",
            "üî® Building model architecture...\n",
            "\n",
            "‚öôÔ∏è  Compiling model...\n",
            "‚úÖ Model compiled successfully!\n",
            "\n",
            "üìã Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer_1       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ \u001b[38;5;34m3\u001b[0m)                ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ sequential          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ input_layer_1[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mSequential\u001b[0m)        ‚îÇ \u001b[38;5;34m3\u001b[0m)                ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ rescaling           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mRescaling\u001b[0m)         ‚îÇ \u001b[38;5;34m3\u001b[0m)                ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ get_item (\u001b[38;5;33mGetItem\u001b[0m)  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m)  ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ rescaling[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ get_item_1          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m)  ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ rescaling[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mGetItem\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ get_item_2          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m)  ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ rescaling[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mGetItem\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ stack (\u001b[38;5;33mStack\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   ‚îÇ\n",
              "‚îÇ                     ‚îÇ \u001b[38;5;34m3\u001b[0m)                ‚îÇ            ‚îÇ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], ‚îÇ\n",
              "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ get_item_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ add (\u001b[38;5;33mAdd\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ stack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       ‚îÇ\n",
              "‚îÇ                     ‚îÇ \u001b[38;5;34m3\u001b[0m)                ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ resnet50            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      ‚îÇ \u001b[38;5;34m23,587,712\u001b[0m ‚îÇ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mFunctional\u001b[0m)        ‚îÇ \u001b[38;5;34m2048\u001b[0m)             ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ global_average_poo‚Ä¶ ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mGlobalAveragePool‚Ä¶\u001b[0m ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout (\u001b[38;5;33mDropout\u001b[0m)   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ global_average_p‚Ä¶ ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        ‚îÇ     \u001b[38;5;34m30,735\u001b[0m ‚îÇ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)        </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape      </span>‚îÉ<span style=\"font-weight: bold\">    Param # </span>‚îÉ<span style=\"font-weight: bold\"> Connected to      </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer_1       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ sequential          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ rescaling           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)  ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ rescaling[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ get_item_1          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)  ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ rescaling[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ get_item_2          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)  ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ rescaling[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ stack (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Stack</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   ‚îÇ\n",
              "‚îÇ                     ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                ‚îÇ            ‚îÇ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], ‚îÇ\n",
              "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ get_item_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ stack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       ‚îÇ\n",
              "‚îÇ                     ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ resnet50            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> ‚îÇ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ global_average_poo‚Ä¶ ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool‚Ä¶</span> ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ global_average_p‚Ä¶ ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">30,735</span> ‚îÇ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,618,447\u001b[0m (90.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,618,447</span> (90.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,735\u001b[0m (120.06 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,735</span> (120.06 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# Verify required variables are defined\n",
        "required_vars = ['num_classes', 'class_names', 'data_augmentation']\n",
        "missing_vars = [v for v in required_vars if v not in globals()]\n",
        "\n",
        "if missing_vars:\n",
        "    raise NameError(f\"Missing required variables: {missing_vars}. Please run previous cells first.\")\n",
        "\n",
        "print(\"üèóÔ∏è  Building ResNet50 Transfer Learning Model...\")\n",
        "print(f\"   - Number of classes: {num_classes}\")\n",
        "print(f\"   - Input shape: (224, 224, 3)\")\n",
        "\n",
        "try:\n",
        "    # Load pre-trained ResNet50 base model\n",
        "    print(\"\\nüì• Loading pre-trained ResNet50 (ImageNet weights)...\")\n",
        "    base_model = ResNet50(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        input_shape=(224, 224, 3)\n",
        "    )\n",
        "\n",
        "    # Freeze base model layers\n",
        "    base_model.trainable = False\n",
        "    print(\"‚úÖ Base model loaded and frozen\")\n",
        "\n",
        "    # Build the model\n",
        "    print(\"\\nüî® Building model architecture...\")\n",
        "    inputs = layers.Input(shape=(224, 224, 3))\n",
        "\n",
        "    # Apply data augmentation first (works on [0, 1] range)\n",
        "    x = data_augmentation(inputs)\n",
        "\n",
        "    # Scale from [0, 1] to [0, 255] for ResNet preprocessing\n",
        "    x = layers.Rescaling(255.0)(x)\n",
        "\n",
        "    # Apply ResNet preprocessing (normalizes to ImageNet stats)\n",
        "    x = tf.keras.applications.resnet.preprocess_input(x)\n",
        "\n",
        "    # Pass through base model\n",
        "    x = base_model(x, training=False)\n",
        "\n",
        "    # Add classification head\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model_resnet = Model(inputs, outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    print(\"\\n‚öôÔ∏è  Compiling model...\")\n",
        "    model_resnet.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    print(\"‚úÖ Model compiled successfully!\")\n",
        "    print(\"\\nüìã Model Summary:\")\n",
        "    model_resnet.summary()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error building model: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b8ad8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6b8ad8c",
        "outputId": "fc266083-61f6-4d95-b175-c230817d0aaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m468/516\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m4:53\u001b[0m 6s/step - accuracy: 0.1218 - loss: 499.8322"
          ]
        }
      ],
      "source": [
        "history_resnet = model_resnet.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_test_ds,\n",
        "    epochs=10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd82e4f0",
      "metadata": {
        "id": "cd82e4f0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create models directory if it doesn't exist\n",
        "models_dir = \"models\"\n",
        "if not os.path.exists(models_dir):\n",
        "    os.makedirs(models_dir)\n",
        "    print(f\"üìÅ Created directory: {models_dir}\")\n",
        "\n",
        "# Save the model\n",
        "model_path = os.path.join(models_dir, \"resnet50.h5\")\n",
        "\n",
        "try:\n",
        "    if 'model_resnet' not in globals():\n",
        "        raise NameError(\"model_resnet not defined. Please train the model first.\")\n",
        "\n",
        "    print(f\"üíæ Saving model to: {model_path}\")\n",
        "    model_resnet.save(model_path)\n",
        "    print(\"‚úÖ Model saved successfully!\")\n",
        "\n",
        "    # Verify the file was created\n",
        "    if os.path.exists(model_path):\n",
        "        file_size = os.path.getsize(model_path) / (1024 * 1024)  # Size in MB\n",
        "        print(f\"   File size: {file_size:.2f} MB\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  WARNING: Model file not found after saving!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error saving model: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9daf8f8",
      "metadata": {
        "id": "c9daf8f8"
      },
      "outputs": [],
      "source": [
        "print(\"changes\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}